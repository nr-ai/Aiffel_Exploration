{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영어 > 프랑스어 번역기 (단어 레벨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import re    \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수: 178009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16465</th>\n",
       "      <td>That's so ironic.</td>\n",
       "      <td>C'est tellement ironique !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99069</th>\n",
       "      <td>I'm not the one who should go.</td>\n",
       "      <td>Je ne suis pas celui qui devrait y aller.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19127</th>\n",
       "      <td>I don't like eggs.</td>\n",
       "      <td>Je n'aime pas les œufs.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59781</th>\n",
       "      <td>You should have seen me.</td>\n",
       "      <td>Tu aurais dû me voir !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136745</th>\n",
       "      <td>The man caught the girl by the wrist.</td>\n",
       "      <td>L'homme attrapa la fille par le poignet.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          eng  \\\n",
       "16465                       That's so ironic.   \n",
       "99069          I'm not the one who should go.   \n",
       "19127                      I don't like eggs.   \n",
       "59781                You should have seen me.   \n",
       "136745  The man caught the girl by the wrist.   \n",
       "\n",
       "                                              fra  \\\n",
       "16465                  C'est tellement ironique !   \n",
       "99069   Je ne suis pas celui qui devrait y aller.   \n",
       "19127                     Je n'aime pas les œufs.   \n",
       "59781                      Tu aurais dû me voir !   \n",
       "136745   L'homme attrapa la fille par le poignet.   \n",
       "\n",
       "                                                       cc  \n",
       "16465   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "99069   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "19127   CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "59781   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "136745  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수:', len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3807</th>\n",
       "      <td>I thought so.</td>\n",
       "      <td>Je m'en suis douté.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>I like this.</td>\n",
       "      <td>Je l'apprécie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31886</th>\n",
       "      <td>The idea is not bad.</td>\n",
       "      <td>L'idée n'est pas mauvaise.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>It's clean.</td>\n",
       "      <td>C'est propre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6888</th>\n",
       "      <td>We want to go.</td>\n",
       "      <td>Nous voulons y aller.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        eng                         fra\n",
       "3807          I thought so.         Je m'en suis douté.\n",
       "2291           I like this.              Je l'apprécie.\n",
       "31886  The idea is not bad.  L'idée n'est pas mauvaise.\n",
       "1538            It's clean.               C'est propre.\n",
       "6888         We want to go.       Nous voulons y aller."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][:33000]\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Go.', 'Hi.', 'Hi.', ..., 'What would Tom need?',\n",
       "       'What would you like?', 'What would you like?'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_np_eng= lines['eng'].to_numpy()\n",
    "lines_np_fra= lines['fra'].to_numpy()\n",
    "lines_np_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = '<start> '\n",
    "eos_token = ' <end>'\n",
    "\n",
    "def preprocess_line(line, plus_token = True):\n",
    "    # 소문자로 변경하기\n",
    "    line = line.lower().strip()\n",
    "    # 구두점(Punctuation)을 단어와 분리하기\n",
    "    line = re.sub(r\"([?.!,¿])\", r\" \\1 \", line)\n",
    "    line = re.sub(r'[\" \"]+', \" \", line)\n",
    "    line = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", line)\n",
    "\n",
    "    line = line.strip()\n",
    "    \n",
    "    if plus_token == True:\n",
    "        line = sos_token + line + eos_token\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer(\n",
    "        num_words=7000,  \n",
    "        filters=' ',   \n",
    "        oov_token=\"<unk>\"  \n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)  \n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_lines = []\n",
    "fra_lines = []\n",
    "\n",
    "# eng_lines.append(lines.eng.apply(lambda x : preprocess_line(x,plus_token = False)))\n",
    "# fra_lines.append(lines.fra.apply(lambda x : preprocess_line(x),))\n",
    "\n",
    "for eng, fra in zip(lines.eng, lines.fra):\n",
    "    if len(eng) == 0: continue\n",
    "    if len(fra) == 0: continue   \n",
    "        \n",
    "    eng_lines.append(preprocess_line(eng, plus_token = False))\n",
    "    fra_lines.append(preprocess_line(fra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(eng_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 93, 13, 3],\n",
       " [2, 1070, 13, 3],\n",
       " [2, 1070, 4, 3],\n",
       " [2, 930, 13, 3],\n",
       " [2, 2192, 13, 3],\n",
       " [2, 53, 7, 3],\n",
       " [2, 11, 621, 13, 3],\n",
       " [2, 101, 510, 13, 3],\n",
       " [2, 19, 176, 13, 3],\n",
       " [2, 2654, 4, 3]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tensor, eng_tokenizer = tokenize(eng_lines)\n",
    "fra_tensor, fra_tokenizer = tokenize(fra_lines)\n",
    "fra_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = eng_tensor\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[char for char in line if char != fra_tokenizer.word_index['<end>']] for line in fra_tensor]\n",
    "# 시작 토큰 제거\n",
    "decoder_target =[[char for char in line if char != fra_tokenizer.word_index['<start>']] for line in fra_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(tensor):\n",
    "    total_data_text = list(tensor)\n",
    "    num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "    max_tokens = max(num_tokens)\n",
    "#     max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "    maxlen = int(max_tokens)\n",
    "    tensor = pad_sequences(tensor, padding='post', maxlen=maxlen)  \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 8)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 16)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 16)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_tensor(encoder_input)\n",
    "decoder_input = pad_tensor(decoder_input)\n",
    "decoder_target = pad_tensor(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index)+1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index)+1\n",
    "\n",
    "max_eng_seq_len = encoder_input.shape[1]\n",
    "max_fra_seq_len = decoder_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 8)\n",
      "(30000, 16)\n",
      "(30000, 16)\n",
      "(3000, 8)\n",
      "(3000, 16)\n",
      "(3000, 16)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50\n",
    "hidden_size = 50\n",
    "# 인코더에서 사용할 임베딩 층 사용 예시\n",
    "encoder_inputs = Input(shape=(None, ), name='encoder_input')\n",
    "enc_emb =  Embedding(eng_vocab_size, embedding_size,\n",
    "                    input_length=max_eng_seq_len)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_size, dropout = 0.5, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, ), name='decoder_input')\n",
    "dec_emb =  Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(hidden_size, dropout = 0.5, return_sequences = True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 50)     233200      encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 50)     366400      decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, None, 50)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "masking_3 (Masking)             (None, None, 50)     0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50), (None,  20200       masking_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 50), ( 20200       masking_3[0][0]                  \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 7328)   373728      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,013,728\n",
      "Trainable params: 1,013,728\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 2.1249 - val_loss: 1.6365\n",
      "Epoch 2/15\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 1.5692 - val_loss: 1.4816\n",
      "Epoch 3/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.4500 - val_loss: 1.3930\n",
      "Epoch 4/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.3802 - val_loss: 1.3391\n",
      "Epoch 5/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.3317 - val_loss: 1.2996\n",
      "Epoch 6/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.2947 - val_loss: 1.2659\n",
      "Epoch 7/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.2649 - val_loss: 1.2384\n",
      "Epoch 8/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.2404 - val_loss: 1.2196\n",
      "Epoch 9/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.2173 - val_loss: 1.1948\n",
      "Epoch 10/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.1996 - val_loss: 1.1822\n",
      "Epoch 11/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.1888 - val_loss: 1.1781\n",
      "Epoch 12/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.1874 - val_loss: 1.1841\n",
      "Epoch 13/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.1922 - val_loss: 1.1888\n",
      "Epoch 14/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.1846 - val_loss: 1.1758\n",
      "Epoch 15/15\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.1708 - val_loss: 1.1627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efe9deb7c90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], \n",
    "          y=decoder_target_train, \n",
    "          validation_data = ([encoder_input_test, decoder_input_test], \n",
    "                             decoder_target_test),\n",
    "          batch_size=32, \n",
    "          epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 50)          233200    \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, None, 50)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                [(None, 50), (None, 50),  20200     \n",
      "=================================================================\n",
      "Total params: 253,400\n",
      "Trainable params: 253,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(embedding_size,))\n",
    "decoder_state_input_c = Input(shape=(embedding_size,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 50)     366400      decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 50), ( 20200       embedding_4[0][0]                \n",
      "                                                                 input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 7328)   373728      lstm_3[2][0]                     \n",
      "==================================================================================================\n",
      "Total params: 760,328\n",
      "Trainable params: 760,328\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2] + decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <start>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = fra2idx['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + idx2eng[i]+' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=fra2idx['<start>']) and i!=fra2idx['<end>']):\n",
    "            temp = temp + idx2fra[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: let s take a look . \n",
      "정답 문장: jetons y un coup d il . \n",
      "번역기가 번역한 문장:  un un un . . . \n",
      "-----------------------------------\n",
      "입력 문장: i see you are awake . \n",
      "정답 문장: je vois que tu es r veill . \n",
      "번역기가 번역한 문장:  je vous que tu \n",
      "-----------------------------------\n",
      "입력 문장: count up to thirty . \n",
      "정답 문장: compte jusqu trente . \n",
      "번역기가 번역한 문장:  l les . . . . . \n",
      "-----------------------------------\n",
      "입력 문장: we broke up . \n",
      "정답 문장: nous nous sommes s par s . \n",
      "번역기가 번역한 문장:  nous nous . . . \n",
      "-----------------------------------\n",
      "입력 문장: yours was better . \n",
      "정답 문장: la tienne tait meilleure . \n",
      "번역기가 번역한 문장:  la tait tait la \n"
     ]
    }
   ],
   "source": [
    "for seq_index in [1,3,713,2114,735]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', seq2src(encoder_input_test[seq_index]))\n",
    "    print('정답 문장:', seq2tar(decoder_input_test[seq_index]))\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 느낀점\n",
    "1. 코드를 복붙 위주로 많이 하다보니까, 틀렸을 때 뭐가 틀렸는지 잘 모르겠다.\n",
    "2. 아직 개념이 정확하지 않은 것 같다.\n",
    "3. 다시 복습이 필요하다..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
